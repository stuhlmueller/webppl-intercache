- generatePredictions for non-input values as well
- test with degree 3 and 4 polynomial distOnFuncs on (linear) binomial model, visualize
- geom_smooth: how to get actual 95% confidence interval, or something like that?

- look at predictions when we only have few data points from slowFunc

- test with binomial variance (or some other non-linear function)

- verify that, if family of approximating functions is too limited (e.g. f(x)=1, f(x)=c), we don't converge to using the cache
  - if we do converge to using the cache, think about how to fix it

- test with polynomial distOnFuncs on mh's data
  1. mh: fix prevalence and prior so that speaker2 is slowFunc of 1 argument
  2. apply intercache to speaker2 with prevalence and prior fixed
  3. generalize our cache to multiple arguments
  4. try with slowFunc of multiple arguments (prevalence, prior, speakerOptimality)


x figure out neural net function prior (andreas)
  - make it work with wider range of input values (of different magnitudes)
  - integrate it with intercache system
  
- test with neural net distOnFuncs on binomial model
- test with neural net distOnFuncs on mh's data

--------------------------------------------------------------------

- (try on spatial language model)

- (look at gpcache notes)

- given parameters that work well, do we actually see an improvement in speed over slowBinomial?
  What is the tradeoff between speed gain and loss in accuracy?

- (optimize variance of guide distribution as well?)

- Then we'll think about approximating families that could deal with this
  - e.g. try simple Bayesian neural nets
    - deterministic weights until final layer (adaptive basis function regression)
    - writing full bayesian neural net may be simpler?
  - e.g. wavelet approximation

- We'll have to do some profiling / think about how to make it fast
  - first, figure out what's slow
  - e.g. don't always condition on all data when doing parameter optimization -
    randomly (?) select fixed-size subset
  - e.g. replace mean and variance with fast js versions
  - e.g. use foreach2


Later:
- explore maximum likelihood version (without prior)
- generalize to multiple arguments; different function approximators
- share variance between polynomial coefficients
